{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementação de Rede Neural Perceptron\n",
        "\n",
        "Renato Barros\n",
        "\n",
        "## Introdução\n",
        "\n",
        "No cenário dinâmico do mundo corporativo, a capacidade de tomar decisões\n",
        "inteligentes e estratégicas é fundamental para o sucesso. Neste\n",
        "contexto, o uso do Perceptron, um algoritmo de aprendizado de máquina\n",
        "inspirado no funcionamento do cérebro humano, pode ser uma ferramenta\n",
        "poderosa para análise de dados e previsão de comportamento.\n",
        "\n",
        "O Perceptron é como um aprendiz dedicado que, ao observar padrões e\n",
        "relações em dados, aprende a fazer previsões e auxiliar na tomada de\n",
        "decisões. Seja na identificação de produtos com potencial de venda, na\n",
        "detecção de atividades fraudulentas ou na personalização da experiência\n",
        "do cliente, ele oferece uma gama de aplicações para impulsionar a\n",
        "eficiência e a inteligência das empresas atuais.\n",
        "\n",
        "## Funcionamento\n",
        "\n",
        "O Perceptron funciona como uma rede neural artificial básica: recebe\n",
        "informações, processa-as e gera um resultado. Esse processamento envolve\n",
        "alguns cálculos matemáticos simples:\n",
        "\n",
        "1.  **Combinação Linear:** Cada informação (representada por um valor\n",
        "    numérico) é multiplicada por um peso, que indica sua importância na\n",
        "    decisão final. Os resultados dessas multiplicações são somados,\n",
        "    gerando um valor intermediário chamado de “soma ponderada”.\n",
        "\n",
        "    Fórmula: `u = (x1 * peso1) + (x2 * peso2) + ...`\n",
        "\n",
        "2.  **Função de Ativação:** A “soma ponderada” (u), calculada na etapa\n",
        "    anterior, é então passada por uma função de ativação, que define o\n",
        "    resultado final do Perceptron. A função de ativação introduz não\n",
        "    linearidade ao modelo, permitindo que ele aprenda relações complexas\n",
        "    entre os dados. No nosso caso, usaremos a função “degrau” (step\n",
        "    function), que funciona como um interruptor:\n",
        "\n",
        "    Fórmula:\n",
        "\n",
        "    `f(u) =       1, se u >= 0      0, se u < 0`\n",
        "\n",
        "    Onde:\n",
        "\n",
        "    -   `f(u)` é a saída da função de ativação.\n",
        "    -   `u` é a “soma ponderada” calculada na etapa anterior.\n",
        "\n",
        "    Em outras palavras, se a “soma ponderada” for maior ou igual a zero,\n",
        "    a saída do Perceptron é 1; caso contrário, a saída é 0. Essa saída\n",
        "    binária pode representar, por exemplo, a recomendação ou não de um\n",
        "    produto, a classificação de um cliente como potencial comprador ou\n",
        "    qualquer outro evento que se deseje prever.\n",
        "\n",
        "3.  **Função Delta:** Após calcular a saída usando a função de ativação,\n",
        "    o Perceptron compara essa saída com a saída desejada (o valor\n",
        "    correto que ele deveria ter previsto). A diferença entre a saída\n",
        "    desejada e a saída real é chamada de “erro”. Para minimizar esse\n",
        "    erro e “aprender” com seus erros, o Perceptron ajusta seus pesos\n",
        "    usando a regra delta (ou regra de Widrow-Hoff). Essa regra ajusta\n",
        "    cada peso proporcionalmente ao erro e à entrada correspondente.\n",
        "\n",
        "    Fórmula:\n",
        "    `novo_peso = peso_atual + (taxa_de_aprendizagem * erro * entrada)`\n",
        "\n",
        "    Onde:\n",
        "\n",
        "    -   `taxa_de_aprendizagem` é um valor pequeno que controla a\n",
        "        velocidade do aprendizado (como visto na seção “Parâmetros e\n",
        "        Dados de Treinamento”).\n",
        "\n",
        "Para ilustrar o funcionamento do Perceptron na prática, temos este\n",
        "código Python que implementa um modelo simples, utilizando exemplos e\n",
        "analogias do universo corporativo.\n",
        "\n",
        "## Parâmetros e Dados de Treinamento\n",
        "\n",
        "Assim como um estagiário precisa de orientação inicial, o Perceptron\n",
        "também precisa de parâmetros iniciais e dados para iniciar seu\n",
        "aprendizado."
      ],
      "id": "b23af1aa-0fff-4728-921c-997ae63d4ecd"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializa os pesos do perceptron (w1 e w2)\n",
        "peso = [0.2, -0.1]\n",
        "# Define a taxa de aprendizagem para o algoritmo\n",
        "taxa_aprendizagem = 0.1\n",
        "# Inicializa o contador de erros totais do perceptron como zero\n",
        "erros_totais = 0.0\n",
        "# Define o limite de épocas (iterações) para o treinamento\n",
        "limite_epocas = 20\n",
        "\n",
        "# Define os dados de treinamento com seus respectivos valores\n",
        "# de entrada (x1 e x2) e a saída desejada (valor de referência)\n",
        "dados_treinamento = [\n",
        "    {\"x1\": 0.5, \"x2\": 0.8, \"saida_desejada\": 1},\n",
        "    {\"x1\": 0.2, \"x2\": 0.4, \"saida_desejada\": 0},\n",
        "]"
      ],
      "id": "e9ee13b3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   **Inicializando os Pesos:** No Perceptron, os “pesos” representam a\n",
        "    importância de cada informação na tomada de decisão. No código,\n",
        "    `peso = [0.2, -0.1]` significa que estamos atribuindo pesos iniciais\n",
        "    aleatórios para duas informações relevantes (x1 e x2).\n",
        "\n",
        "    Digamos, por exemplo, que estamos construindo um modelo para prever\n",
        "    a probabilidade de um produto ser um sucesso de vendas. Nesse caso,\n",
        "    x1 poderia ser o número de avaliações positivas do produto e x2 a\n",
        "    quantidade de vezes que ele foi adicionado à lista de desejos dos\n",
        "    clientes. Os pesos (0.2 e -0.1) refletem a importância relativa\n",
        "    dessas informações na decisão final.\n",
        "\n",
        "-   **Definindo a Taxa de Aprendizagem:** A `taxa_aprendizagem = 0.1`\n",
        "    controla a velocidade com que o Perceptron ajusta seus pesos a cada\n",
        "    erro. Imagine que a taxa de aprendizado é como a sensibilidade de\n",
        "    uma balança.\n",
        "\n",
        "    Uma taxa alta significa que o modelo fará grandes ajustes nos pesos\n",
        "    a cada erro, o que pode acelerar o aprendizado, mas também torná-lo\n",
        "    instável. Uma taxa baixa, por outro lado, fará com que o modelo faça\n",
        "    pequenos ajustes, tornando o processo mais lento, porém mais\n",
        "    preciso.\n",
        "\n",
        "-   **Contabilizando os Erros:** `erros_totais = 0.0` funciona como um\n",
        "    contador de erros. Durante o treinamento, o Perceptron compara suas\n",
        "    previsões com os valores reais, e cada erro é contabilizado. Esse\n",
        "    contador nos ajuda a avaliar o quão bem o modelo está aprendendo.\n",
        "\n",
        "    Imagine um treinamento para o Perceptron identificar potenciais\n",
        "    compradores em um marketplace. A cada vez que o modelo classifica\n",
        "    incorretamente um usuário como comprador ou não comprador, o\n",
        "    contador de erros é incrementado, fornecendo uma medida da precisão\n",
        "    do modelo.\n",
        "\n",
        "-   **Limitando as Épocas de Treinamento:** `limite_epocas = 20` define\n",
        "    o número máximo de vezes que o Perceptron analisará todos os dados\n",
        "    de treinamento. Essa é uma forma de controlar o tempo de treinamento\n",
        "    do modelo.\n",
        "\n",
        "    No caso de um Perceptron que aprende a prever o tempo de entrega de\n",
        "    um produto com base na localização do vendedor e do comprador, tipo\n",
        "    de frete e histórico de entregas. Cada época de treinamento seria\n",
        "    como analisar todas as entregas já realizadas, permitindo que o\n",
        "    modelo ajuste seus pesos para fazer previsões mais precisas.\n",
        "\n",
        "-   **Fornecendo os Dados de Treinamento:** `dados_treinamento` é a base\n",
        "    do aprendizado do Perceptron. É um conjunto de dados com informações\n",
        "    sobre diferentes eventos, produtos ou usuários, juntamente com a\n",
        "    classificação correta para cada um deles.\n",
        "\n",
        "    Neste código, temos um conjunto de dados (x1, x2) e a indicação do\n",
        "    resultado gerado (`saida_desejada = 1` ou `0`).\n",
        "\n",
        "    Imagine que estamos treinando o Perceptron para identificar produtos\n",
        "    com potencial de viralização. Os dados de treinamento conteriam\n",
        "    informações sobre produtos que se tornaram virais no passado,\n",
        "    juntamente com aqueles que não tiveram o mesmo sucesso.\n",
        "\n",
        "## Treinamento do Perceptron\n",
        "\n",
        "Com os parâmetros definidos e os dados de treinamento preparados, o\n",
        "Perceptron inicia seu processo de aprendizado. Esse processo funciona\n",
        "como um jogo de ajuste fino, onde o Perceptron tenta encontrar os\n",
        "melhores valores para os pesos, de forma a fazer previsões cada vez mais\n",
        "precisas."
      ],
      "id": "65460b06-42b1-4651-927a-be51f47fe7f4"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Época: 1\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.20, W2: -0.10 | Y: 1, Y-predito: 1 | Erro: 0, Erro acumulado: 0.0\n",
            " Ajuste de pesos: Não foi necessário.\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.20, W2: -0.10 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 1.0\n",
            " Ajuste de pesos: Novo W1 = 0.18, Novo W2 = -0.14\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 2\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.18, W2: -0.14 | Y: 1, Y-predito: 0 | Erro: 1, Erro acumulado: 2.0\n",
            " Ajuste de pesos: Novo W1 = 0.23, Novo W2 = -0.06\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.23, W2: -0.06 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 3.0\n",
            " Ajuste de pesos: Novo W1 = 0.21, Novo W2 = -0.10\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 3\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.21, W2: -0.10 | Y: 1, Y-predito: 1 | Erro: 0, Erro acumulado: 3.0\n",
            " Ajuste de pesos: Não foi necessário.\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.21, W2: -0.10 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 4.0\n",
            " Ajuste de pesos: Novo W1 = 0.19, Novo W2 = -0.14\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 4\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.19, W2: -0.14 | Y: 1, Y-predito: 0 | Erro: 1, Erro acumulado: 5.0\n",
            " Ajuste de pesos: Novo W1 = 0.24, Novo W2 = -0.06\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.24, W2: -0.06 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 6.0\n",
            " Ajuste de pesos: Novo W1 = 0.22, Novo W2 = -0.10\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 5\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.22, W2: -0.10 | Y: 1, Y-predito: 1 | Erro: 0, Erro acumulado: 6.0\n",
            " Ajuste de pesos: Não foi necessário.\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.22, W2: -0.10 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 7.0\n",
            " Ajuste de pesos: Novo W1 = 0.20, Novo W2 = -0.14\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 6\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.20, W2: -0.14 | Y: 1, Y-predito: 0 | Erro: 1, Erro acumulado: 8.0\n",
            " Ajuste de pesos: Novo W1 = 0.25, Novo W2 = -0.06\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.25, W2: -0.06 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 9.0\n",
            " Ajuste de pesos: Novo W1 = 0.23, Novo W2 = -0.10\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 7\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.23, W2: -0.10 | Y: 1, Y-predito: 1 | Erro: 0, Erro acumulado: 9.0\n",
            " Ajuste de pesos: Não foi necessário.\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.23, W2: -0.10 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 10.0\n",
            " Ajuste de pesos: Novo W1 = 0.21, Novo W2 = -0.14\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 8\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.21, W2: -0.14 | Y: 1, Y-predito: 0 | Erro: 1, Erro acumulado: 11.0\n",
            " Ajuste de pesos: Novo W1 = 0.26, Novo W2 = -0.06\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.26, W2: -0.06 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 12.0\n",
            " Ajuste de pesos: Novo W1 = 0.24, Novo W2 = -0.10\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 9\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.24, W2: -0.10 | Y: 1, Y-predito: 1 | Erro: 0, Erro acumulado: 12.0\n",
            " Ajuste de pesos: Não foi necessário.\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.24, W2: -0.10 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 13.0\n",
            " Ajuste de pesos: Novo W1 = 0.22, Novo W2 = -0.14\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 10\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.22, W2: -0.14 | Y: 1, Y-predito: 0 | Erro: 1, Erro acumulado: 14.0\n",
            " Ajuste de pesos: Novo W1 = 0.27, Novo W2 = -0.06\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.27, W2: -0.06 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 15.0\n",
            " Ajuste de pesos: Novo W1 = 0.25, Novo W2 = -0.10\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 11\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.25, W2: -0.10 | Y: 1, Y-predito: 1 | Erro: 0, Erro acumulado: 15.0\n",
            " Ajuste de pesos: Não foi necessário.\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.25, W2: -0.10 | Y: 0, Y-predito: 1 | Erro: -1, Erro acumulado: 16.0\n",
            " Ajuste de pesos: Novo W1 = 0.23, Novo W2 = -0.14\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Época: 12\n",
            "\n",
            " X1: 0.5, X2: 0.8 | W1: 0.23, W2: -0.14 | Y: 1, Y-predito: 1 | Erro: 0, Erro acumulado: 16.0\n",
            " Ajuste de pesos: Não foi necessário.\n",
            "\n",
            " X1: 0.2, X2: 0.4 | W1: 0.23, W2: -0.14 | Y: 0, Y-predito: 0 | Erro: 0, Erro acumulado: 16.0\n",
            " Ajuste de pesos: Não foi necessário.\n",
            "\n",
            "-=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=--=-\n",
            "\n",
            " Modelo treinado com sucesso na época 12! Erro zero atingido.\n",
            " Valores ideais de peso: W1 = 0.23, W2 = -0.14\n"
          ]
        }
      ],
      "source": [
        "# Inicia o treinamento do Perceptron\n",
        "for epoca in range(1, limite_epocas + 1):\n",
        "    print(f\"\\n Época: {epoca}\\n\")\n",
        "    # Sinaliza se houve erro na época atual, inicialmente definido como False\n",
        "    erro_na_epoca = False\n",
        "\n",
        "    # Itera sobre cada dado de treinamento\n",
        "    for dado in dados_treinamento:\n",
        "        # Extrai os valores de entrada e o valor de referência do dado atual\n",
        "        x1 = dado[\"x1\"]\n",
        "        x2 = dado[\"x2\"]\n",
        "        saida_desejada = dado[\"saida_desejada\"]\n",
        "\n",
        "        # Exibe os valores dos pesos atuais\n",
        "        w1 = peso[0]\n",
        "        w2 = peso[1]\n",
        "\n",
        "        # Calcula a saída do perceptron (u)\n",
        "        u = (x1 * peso[0]) + (x2 * peso[1])\n",
        "        # Aplica a função de ativação (step function):\n",
        "        # se u >= 0, valor_saida = 1, caso contrário, valor_saida = 0\n",
        "        valor_saida = 1 if u >= 0 else 0\n",
        "\n",
        "        # Calcula o erro: diferença entre o valor de referência e a saída do perceptron\n",
        "        erro = saida_desejada - valor_saida\n",
        "\n",
        "        # Acumula o erro total\n",
        "        erros_totais += abs(erro)\n",
        "\n",
        "        # Se houve erro na iteração atual, define erro_na_epoca como True\n",
        "        if erro != 0:\n",
        "            erro_na_epoca = True\n",
        "            # Ajusta os pesos (w1 e w2) usando a regra delta\n",
        "            peso[0] += taxa_aprendizagem * erro * x1\n",
        "            peso[1] += taxa_aprendizagem * erro * x2\n",
        "\n",
        "        # Mostra as informações da iteração atual (época, entradas, saída, pesos)\n",
        "        print(\n",
        "            f\" X1: {x1:.1f}, X2: {x2:.1f} | W1: {w1:.2f}, W2: {w2:.2f} | Y: {\n",
        "                saida_desejada}, \"\n",
        "            f\"Y-predito: {valor_saida} | Erro: {\n",
        "                erro}, Erro acumulado: {erros_totais}\"\n",
        "        )\n",
        "        if erro_na_epoca:\n",
        "            print(\n",
        "                f\" Ajuste de pesos: Novo W1 = {\n",
        "                    peso[0]:.2f}, Novo W2 = {peso[1]:.2f}\\n\"\n",
        "            )\n",
        "        if not erro_na_epoca:\n",
        "            print(\" Ajuste de pesos: Não foi necessário.\\n\")\n",
        "    print(\"-=-\" * 31)\n",
        "\n",
        "    # Verifica o critério de parada: se não houve erro na época (erro_na_epoca = False)\n",
        "    if not erro_na_epoca:\n",
        "        # Imprime mensagem de sucesso, indicando a época em que o erro zero foi atingido\n",
        "        print(\n",
        "            f\"\\n Modelo treinado com sucesso na época {\n",
        "                epoca}! Erro zero atingido.\"\n",
        "        )\n",
        "        # Imprime os valores finais dos pesos (w1 e w2)\n",
        "        print(\n",
        "            f\" Valores ideais de peso: W1 = {\n",
        "                peso[0]:.2f}, W2 = {peso[1]:.2f}\\n\"\n",
        "        )\n",
        "        # Encerra o loop de treinamento\n",
        "        break\n",
        "# Caso contrário, se o loop atingir o limite de épocas sem sucesso\n",
        "else:\n",
        "    # Imprime mensagem informando que o limite de épocas foi atingido\n",
        "    print(\n",
        "        f\"\\n O limite de {\n",
        "            limite_epocas} épocas foi atingido sem alcançar erro zero.\"\n",
        "    )\n",
        "    # Indica que o perceptron pode não ter convergido\n",
        "    print(\" O perceptron não pôde ser treinado com sucesso.\\n\")"
      ],
      "id": "898fc876"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explicação do Código:\n",
        "\n",
        "O código acima representa o cerne do processo de treinamento do\n",
        "Perceptron, um ciclo iterativo de aprendizado que se repete a cada\n",
        "época, refinando os pesos do modelo para minimizar os erros de previsão.\n",
        "Vamos analisar cada etapa em detalhes:\n",
        "\n",
        "1.  **Controlando as Épocas:** O primeiro laço `for` controla o número\n",
        "    de épocas de treinamento, onde cada época funciona como um ciclo\n",
        "    completo de aprendizado, no qual o Perceptron analisa todos os dados\n",
        "    de treinamento, ajusta seus pesos e calcula o erro total. O limite\n",
        "    de épocas, definido anteriormente como 20, determina o número máximo\n",
        "    desses ciclos.\n",
        "\n",
        "2.  **Aplicando os Dados de Treinamento:** Dentro de cada época, o\n",
        "    segundo laço `for` percorre cada dado de treinamento\n",
        "    individualmente. É como se o Perceptron estivesse examinando cada\n",
        "    exemplo de produto, um por um, para aprender com suas\n",
        "    características (x1, x2) e sua classificação correta\n",
        "    (`saida_desejada`).\n",
        "\n",
        "3.  **Extraindo as Informações:** Para cada produto nos dados de\n",
        "    treinamento, o código extrai suas características (x1, x2) e a\n",
        "    classificação correta (`saida_desejada`). Essas informações serão\n",
        "    usadas para calcular a saída do Perceptron e, posteriormente,\n",
        "    ajustar os pesos.\n",
        "\n",
        "4.  **Armazenando os Pesos Atuais:** As variáveis `w1` e `w2` armazenam\n",
        "    os valores atuais dos pesos. Isso é feito para facilitar a\n",
        "    visualização dos pesos durante o processo de treinamento.\n",
        "\n",
        "5.  **Calculando a Saída do Perceptron:** Aqui é aplicada a fórmula\n",
        "    matemática do Perceptron. A “soma ponderada” (u) é calculada\n",
        "    multiplicando as características do produto (x1, x2) pelos seus\n",
        "    respectivos pesos (w1, w2) e somando os resultados. No caso do\n",
        "    exemplo da tentativa de prever se um produto irá viralizar, essa\n",
        "    soma ponderada representa a “avaliação” do Perceptron sobre o\n",
        "    produto, indicando sua propensão a ser um sucesso de vendas ou não.\n",
        "\n",
        "6.  **Aplicando a Função de Ativação:** A “soma ponderada” (u) é então\n",
        "    passada pela função de ativação “degrau”. Essa função define a saída\n",
        "    do Perceptron (`valor_saida`) com base na “soma ponderada”: se u for\n",
        "    maior ou igual a zero, a saída é 1 (sucesso de vendas); caso\n",
        "    contrário, a saída é 0 (não sucesso).\n",
        "\n",
        "7.  **Calculando o Erro:** O Perceptron compara sua previsão\n",
        "    (`valor_saida`) com a classificação correta (`saida_desejada`). A\n",
        "    diferença entre esses valores representa o “erro” do modelo. É a\n",
        "    partir do erro que o Perceptron ajusta seus pesos, buscando\n",
        "    minimizar a diferença entre suas previsões e os valores reais.\n",
        "\n",
        "8.  **Ajustando os Pesos:** Se houver erro na previsão, os pesos (w1,\n",
        "    w2) são ajustados usando a regra delta. Essa regra utiliza a taxa de\n",
        "    aprendizagem para controlar o tamanho do ajuste. O objetivo do\n",
        "    ajuste é fazer com que o Perceptron se aproxime da classificação\n",
        "    correta a cada iteração.\n",
        "\n",
        "9.  **Mostrando as Informações da Época:** O código exibe as informações\n",
        "    da época atual, incluindo as entradas e os pesos usados na\n",
        "    interação, a saída desejada, a saída predita, o erro, o erro\n",
        "    acumulado e o ajuste de pesos. Essa visualização detalhada permite\n",
        "    acompanhar o progresso do treinamento e entender como os pesos são\n",
        "    ajustados a cada época.\n",
        "\n",
        "10. **Verificando o Critério de Parada:** Ao final de cada época, o\n",
        "    código verifica se o Perceptron atingiu o erro zero, ou seja, se ele\n",
        "    classificou corretamente todos os dados de treinamento. Se o erro\n",
        "    zero for atingido, o treinamento é interrompido com sucesso, e os\n",
        "    pesos finais do modelo são exibidos. Caso contrário, o treinamento\n",
        "    continua até que o limite de épocas seja atingido.\n",
        "\n",
        "O processo de treinamento do Perceptron busca encontrar um ponto de\n",
        "equilíbrio, ajustando os pesos de forma que o erro seja minimizado. Esse\n",
        "processo de aprendizado, embora relativamente simples, é a base para o\n",
        "desenvolvimento de modelos mais complexos e poderosos de inteligência\n",
        "artificial.\n",
        "\n",
        "## Interpretação dos Resultados\n",
        "\n",
        "A análise do resultado gerado ao rodar o modelo nos permite avaliar o\n",
        "processo de aprendizado do Perceptron e determinar se o treinamento foi\n",
        "bem-sucedido. O sucesso do treinamento é definido pela capacidade do\n",
        "modelo de classificar corretamente os dados de treinamento, o que, nesse\n",
        "caso, significa atingir o erro zero.\n",
        "\n",
        "Observando os resultados, é possível identificar que o Perceptron\n",
        "atingiu o erro zero na época 12. Isso significa que o modelo precisou\n",
        "passar 12 vezes pelos dados de treinamento para encontrar um conjunto de\n",
        "pesos que tivesse capacidade de classificar os dados corretamente.\n",
        "\n",
        "A necessidade de várias épocas para alcançar o erro zero significa que,\n",
        "apesar dos dados de treinamento poderem ser separados em duas classes\n",
        "por uma linha (linearmente separáveis), essa separação não era\n",
        "imediatamente óbvia para o Perceptron com os pesos aleatórios que ele\n",
        "recebeu no início do treinamento. Sendo assim, os pesos iniciais não\n",
        "eram adequados para classificar os dados corretamente, exigindo um\n",
        "processo de ajuste gradual ao longo das épocas.\n",
        "\n",
        "Em cada uma dessas épocas, o Perceptron ajustou seus pesos em resposta\n",
        "aos erros de classificação, buscando minimizar a distância entre suas\n",
        "previsões e os valores reais. A cada ajuste, o modelo se aproximava da\n",
        "solução ideal, até que, na época 12, todos os dados foram classificados\n",
        "corretamente.\n",
        "\n",
        "Os pesos finais encontrados, `W1 = 0.23` e `W2 = -0.14`, refletem o\n",
        "conhecimento adquirido pelo modelo durante o treinamento. A análise\n",
        "desses pesos nos permite entender como o Perceptron aprendeu a\n",
        "classificar os dados:\n",
        "\n",
        "-   **W1 positivo (0.23):** Indica que a característica x1 tem uma\n",
        "    influência positiva na decisão final do modelo. Um valor maior para\n",
        "    x1 aumenta a propensão do Perceptron a gerar uma saída “1”, que,\n",
        "    dependendo do problema em questão, pode representar a recomendação\n",
        "    de um produto, a classificação de um cliente como potencial\n",
        "    comprador, ou qualquer outro evento que se deseje prever.\n",
        "\n",
        "-   **W2 negativo (-0.14):** Indica que a característica x2 tem uma\n",
        "    influência negativa na decisão final. Diferente de x1, um valor\n",
        "    maior para x2 diminui a propensão do modelo a gerar uma saída “1”,\n",
        "    atuando como um contraponto à influência de x1.\n",
        "\n",
        "Essa análise dos pesos demonstra a capacidade do Perceptron de ponderar\n",
        "diferentes características e aprender relações complexas entre os dados.\n",
        "\n",
        "É fundamental destacar que, se o limite de épocas fosse definido como 3,\n",
        "o treinamento seria interrompido antes do Perceptron atingir o erro\n",
        "zero. Com apenas 3 épocas, o modelo não teria tempo suficiente para\n",
        "ajustar seus pesos de forma a classificar corretamente todos os dados de\n",
        "treinamento. Os pesos finais, nesse cenário, representariam uma solução\n",
        "subótima, comprometendo a capacidade de generalização do modelo, ou\n",
        "seja, sua capacidade de ter um bom desempenho em dados não vistos\n",
        "durante o treinamento.\n",
        "\n",
        "## Conclusão\n",
        "\n",
        "O Perceptron, mesmo em sua forma mais básica, demonstra o potencial do\n",
        "aprendizado de máquina para solucionar problemas complexos em uma\n",
        "variedade de setores. Suas aplicações, que vão desde a segmentação\n",
        "precisa de clientes e a previsão acurada da demanda até a recomendação\n",
        "personalizada de produtos e a otimização da experiência de busca,\n",
        "ilustram sua capacidade de extrair padrões intrincados de dados e gerar\n",
        "previsões robustas. Com isso, o Perceptron abre um leque de\n",
        "oportunidades para aprimorar a eficiência operacional, personalizar a\n",
        "interação com o cliente, impulsionar as vendas e, sendo assim, auxiliar\n",
        "na construção de um ecossistema de negócios mais inteligente, ágil e\n",
        "responsivo às atuais demandas do mercado."
      ],
      "id": "6fb3d8f1-304f-477e-a07c-09a5f90c9f36"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/home/renato/.asdf/installs/python/3.12.5/share/jupyter/kernels/python3"
    }
  }
}